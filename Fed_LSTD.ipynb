{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbi2bFrOp3ec",
        "outputId": "2b2dfbe9-4732-4b99-bc52-175a4d1f8a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Federated Round 1 ---\n",
            "Hospital 1 local theta: [-0.169 -0.01   0.21   0.466 -0.478]\n",
            "Hospital 2 local theta: [-0.242 -0.043  0.168  0.522 -0.43 ]\n",
            "Hospital 3 local theta: [-0.188  0.003  0.188  0.441 -0.421]\n",
            "Aggregated global theta: [-0.2   -0.017  0.189  0.476 -0.443]\n",
            "\n",
            "--- Federated Round 2 ---\n",
            "Hospital 1 local theta: [-0.197 -0.04   0.192  0.452 -0.397]\n",
            "Hospital 2 local theta: [-0.175  0.061  0.234  0.428 -0.519]\n",
            "Hospital 3 local theta: [-0.139  0.042  0.204  0.436 -0.504]\n",
            "Aggregated global theta: [-0.17   0.021  0.21   0.438 -0.473]\n",
            "\n",
            "--- Federated Round 3 ---\n",
            "Hospital 1 local theta: [-0.241  0.004  0.205  0.443 -0.407]\n",
            "Hospital 2 local theta: [-0.171  0.031  0.234  0.428 -0.493]\n",
            "Hospital 3 local theta: [-0.172  0.021  0.207  0.451 -0.481]\n",
            "Aggregated global theta: [-0.195  0.019  0.215  0.441 -0.46 ]\n",
            "\n",
            "--- Federated Round 4 ---\n",
            "Hospital 1 local theta: [-0.231 -0.003  0.197  0.457 -0.416]\n",
            "Hospital 2 local theta: [-0.222  0.012  0.251  0.446 -0.48 ]\n",
            "Hospital 3 local theta: [-0.115  0.029  0.221  0.396 -0.478]\n",
            "Aggregated global theta: [-0.189  0.013  0.223  0.433 -0.458]\n",
            "\n",
            "--- Federated Round 5 ---\n",
            "Hospital 1 local theta: [-0.176 -0.013  0.197  0.439 -0.423]\n",
            "Hospital 2 local theta: [-0.153  0.027  0.193  0.435 -0.467]\n",
            "Hospital 3 local theta: [-0.223 -0.055  0.216  0.479 -0.425]\n",
            "Aggregated global theta: [-0.184 -0.013  0.202  0.451 -0.438]\n",
            "\n",
            "Final Federated Policy Evaluation (theta values):\n",
            "State 0: -0.184\n",
            "State 1: -0.013\n",
            "State 2: 0.202\n",
            "State 3: 0.451\n",
            "State 4: -0.438\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Hypothetical medical environment for patient treatment decision-making\n",
        "class MedicalEnv:\n",
        "    def __init__(self, num_states=5):\n",
        "        self.num_states = num_states\n",
        "        self.terminal_state = num_states - 1\n",
        "\n",
        "    def step(self, state, action):\n",
        "        # Transition model (simplified for demonstration)\n",
        "        next_state = min(state + action, self.terminal_state)\n",
        "        reward = 1.0 if next_state == self.terminal_state else -0.1\n",
        "        done = next_state == self.terminal_state\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def reset(self):\n",
        "        return 0  # initial patient state\n",
        "\n",
        "# Feature representation (one-hot encoding for simplicity)\n",
        "def feature(s, num_states):\n",
        "    vec = np.zeros(num_states)\n",
        "    vec[s] = 1\n",
        "    return vec\n",
        "\n",
        "# LSTD policy evaluation\n",
        "def LSTD(samples, num_states, gamma=0.95):\n",
        "    A = np.zeros((num_states, num_states))\n",
        "    b = np.zeros(num_states)\n",
        "\n",
        "    for s, r, s_next in samples:\n",
        "        phi_s = feature(s, num_states)\n",
        "        phi_s_next = feature(s_next, num_states)\n",
        "        A += np.outer(phi_s, (phi_s - gamma * phi_s_next))\n",
        "        b += phi_s * r\n",
        "\n",
        "    theta = np.linalg.pinv(A) @ b\n",
        "    return theta\n",
        "\n",
        "# Federated averaging\n",
        "def federated_avg(thetas):\n",
        "    return np.mean(thetas, axis=0)\n",
        "\n",
        "# Simulate local learning at hospitals\n",
        "def local_training(env, episodes=20):\n",
        "    samples = []\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            # Simple random policy: action = 1 (treatment) or stay (0)\n",
        "            action = np.random.choice([0, 1])\n",
        "            s_next, reward, done = env.step(s, action)\n",
        "            samples.append((s, reward, s_next))\n",
        "            s = s_next\n",
        "    return samples\n",
        "\n",
        "# Main Federated Learning Loop\n",
        "def federated_lstd(num_hospitals=3, rounds=5):\n",
        "    num_states = 5\n",
        "    global_theta = np.zeros(num_states)\n",
        "\n",
        "    for round in range(rounds):\n",
        "        local_thetas = []\n",
        "        print(f\"\\n--- Federated Round {round+1} ---\")\n",
        "        for hospital in range(num_hospitals):\n",
        "            env = MedicalEnv(num_states)\n",
        "            samples = local_training(env)\n",
        "            theta = LSTD(samples, num_states)\n",
        "            local_thetas.append(theta)\n",
        "            print(f\"Hospital {hospital+1} local theta: {theta.round(3)}\")\n",
        "\n",
        "        # Aggregate using federated averaging\n",
        "        global_theta = federated_avg(local_thetas)\n",
        "        print(f\"Aggregated global theta: {global_theta.round(3)}\")\n",
        "\n",
        "    return global_theta\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    final_theta = federated_lstd()\n",
        "    print(\"\\nFinal Federated Policy Evaluation (theta values):\")\n",
        "    for idx, val in enumerate(final_theta):\n",
        "        print(f\"State {idx}: {val:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIxGLfzeqv3O"
      },
      "source": [
        "This code only implements federated version if you want to play with federated LSTD only. The following code, implements non-federated or centralized version and compares each other. Run the code and compare both. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyl_80YmqgkI",
        "outputId": "1b0b0116-1636-4a98-fa81-b7ac9755466b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Federated LSTD Training ---\n",
            "\n",
            "Final Federated Theta: [-0.188 -0.014  0.192  0.457 -0.432]\n",
            "\n",
            "--- Centralized LSTD Training ---\n",
            "\n",
            "Final Centralized Theta: [-0.163  0.001  0.208  0.442 -0.46 ]\n",
            "\n",
            "--- Theta Comparison (Federated vs. Centralized) ---\n",
            "State 0: Federated: -0.188 | Centralized: -0.163\n",
            "State 1: Federated: -0.014 | Centralized: 0.001\n",
            "State 2: Federated: 0.192 | Centralized: 0.208\n",
            "State 3: Federated: 0.457 | Centralized: 0.442\n",
            "State 4: Federated: -0.432 | Centralized: -0.460\n"
          ]
        }
      ],
      "source": [
        "# Non-Federated Centralized LSTD\n",
        "def centralized_training(env, num_states, episodes=60):  # same total episodes\n",
        "    samples = []\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = np.random.choice([0, 1])\n",
        "            s_next, reward, done = env.step(s, action)\n",
        "            samples.append((s, reward, s_next))\n",
        "            s = s_next\n",
        "    theta = LSTD(samples, num_states)\n",
        "    return theta\n",
        "\n",
        "# Modify the main function to run both versions\n",
        "def compare_federated_vs_centralized(num_hospitals=3, rounds=5):\n",
        "    num_states = 5\n",
        "    global_theta = np.zeros(num_states)\n",
        "\n",
        "    # Federated Learning\n",
        "    print(\"\\n--- Federated LSTD Training ---\")\n",
        "    for round in range(rounds):\n",
        "        local_thetas = []\n",
        "        for hospital in range(num_hospitals):\n",
        "            env = MedicalEnv(num_states)\n",
        "            samples = local_training(env)\n",
        "            theta = LSTD(samples, num_states)\n",
        "            local_thetas.append(theta)\n",
        "        global_theta = federated_avg(local_thetas)\n",
        "\n",
        "    print(f\"\\nFinal Federated Theta: {global_theta.round(3)}\")\n",
        "\n",
        "    # Centralized Learning (single node, equivalent amount of data)\n",
        "    print(\"\\n--- Centralized LSTD Training ---\")\n",
        "    env = MedicalEnv(num_states)\n",
        "    centralized_theta = centralized_training(env, num_states, episodes=num_hospitals*20)\n",
        "    print(f\"\\nFinal Centralized Theta: {centralized_theta.round(3)}\")\n",
        "\n",
        "    # Comparison\n",
        "    print(\"\\n--- Theta Comparison (Federated vs. Centralized) ---\")\n",
        "    for i in range(num_states):\n",
        "        print(f\"State {i}: Federated: {global_theta[i]:.3f} | Centralized: {centralized_theta[i]:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    compare_federated_vs_centralized()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qhjDzIosOY-"
      },
      "source": [
        "Below is the code for synthetic medical data. This code can now be extended to some large medical data such as MIMIC-III with access to good GPUs. First run and understand this code, before going full scale on a realistic medical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mktA30CpsDfm",
        "outputId": "038be999-f954-4f9b-b2c7-63bfe0d75188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Federated LSTD Training ---\n",
            "Round 1: Averaged Theta: [  0.     -7.649 -11.227  -9.307   0.   ]\n",
            "Round 2: Averaged Theta: [  0.     -7.96  -11.963 -10.801   0.   ]\n",
            "Round 3: Averaged Theta: [ -0.     -8.183 -11.197  -9.327   0.   ]\n",
            "Round 4: Averaged Theta: [  0.     -8.789 -11.684  -9.397   0.   ]\n",
            "Round 5: Averaged Theta: [ -0.     -9.397 -11.628  -8.741   0.   ]\n",
            "\n",
            "Final Federated Theta: [ -0.     -9.397 -11.628  -8.741   0.   ]\n",
            "\n",
            "--- Centralized LSTD Training ---\n",
            "\n",
            "Final Centralized Theta: [  0.     -7.152 -11.497  -9.515   0.   ]\n",
            "\n",
            "--- Theta Comparison (Federated vs. Centralized) ---\n",
            "State 0: Federated: -0.000 | Centralized: 0.000\n",
            "State 1: Federated: -9.397 | Centralized: -7.152\n",
            "State 2: Federated: -11.628 | Centralized: -11.497\n",
            "State 3: Federated: -8.741 | Centralized: -9.515\n",
            "State 4: Federated: 0.000 | Centralized: 0.000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MedicalEnv:\n",
        "    \"\"\"\n",
        "    A simple medical decision-making environment.\n",
        "    States: 0 (healthy) to num_states-1 (critical).\n",
        "    Terminal states: 0 (recovered) and num_states-1 (severe condition).\n",
        "    Actions: 0 = no treatment, 1 = treatment.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_states=5):\n",
        "        self.num_states = num_states\n",
        "        self.terminal_states = [0, self.num_states - 1]\n",
        "\n",
        "    def reset(self):\n",
        "        # Initialize state to a value between 1 and num_states-2 (i.e., not already terminal)\n",
        "        s = np.random.randint(1, self.num_states - 1)\n",
        "        return s\n",
        "\n",
        "    def step(self, s, action):\n",
        "        \"\"\"\n",
        "        Simulate a step in the environment.\n",
        "        - Action 1 (treatment): With 70% chance, state improves (decreases by 1),\n",
        "          with 30% chance, state worsens (increases by 1), if possible.\n",
        "        - Action 0 (no treatment): With 50% chance, state worsens (increases by 1),\n",
        "          otherwise stays the same.\n",
        "        A treatment cost is subtracted from the reward.\n",
        "        Reward is defined as negative of the new state (lower is better) and treatment cost.\n",
        "        \"\"\"\n",
        "        if action == 1:  # Treatment applied\n",
        "            if np.random.rand() < 0.7:\n",
        "                s_next = max(s - 1, 0)\n",
        "            else:\n",
        "                s_next = min(s + 1, self.num_states - 1)\n",
        "            cost = 2  # Cost for treatment\n",
        "        else:  # No treatment\n",
        "            if np.random.rand() < 0.5:\n",
        "                s_next = min(s + 1, self.num_states - 1)\n",
        "            else:\n",
        "                s_next = s\n",
        "            cost = 0\n",
        "\n",
        "        # Reward: lower state (better health) gives higher reward; treatment incurs cost.\n",
        "        reward = - s_next - cost\n",
        "\n",
        "        done = s_next in self.terminal_states\n",
        "        return s_next, reward, done\n",
        "\n",
        "def local_training(env, episodes=20):\n",
        "    \"\"\"\n",
        "    Collect samples locally on a single hospital environment.\n",
        "    Each sample is a tuple (state, reward, next_state).\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = np.random.choice([0, 1])\n",
        "            s_next, reward, done = env.step(s, action)\n",
        "            samples.append((s, reward, s_next))\n",
        "            s = s_next\n",
        "    return samples\n",
        "\n",
        "def centralized_training(env, num_states, episodes=60):\n",
        "    \"\"\"\n",
        "    Centralized training: Collect samples over multiple episodes on one environment.\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = np.random.choice([0, 1])\n",
        "            s_next, reward, done = env.step(s, action)\n",
        "            samples.append((s, reward, s_next))\n",
        "            s = s_next\n",
        "    theta = LSTD(samples, num_states)\n",
        "    return theta\n",
        "\n",
        "def LSTD(samples, num_states, gamma=0.9):\n",
        "    \"\"\"\n",
        "    Least-Squares Temporal Difference (LSTD) learning.\n",
        "    Uses one-hot encoding for state features.\n",
        "    Solves: A theta = b, where:\n",
        "      A = sum(phi(s) (phi(s)- gamma phi(s_next))^T)\n",
        "      b = sum(phi(s) * reward)\n",
        "    \"\"\"\n",
        "    A = np.zeros((num_states, num_states))\n",
        "    b = np.zeros(num_states)\n",
        "    for s, reward, s_next in samples:\n",
        "        phi_s = np.zeros(num_states)\n",
        "        phi_s[int(s)] = 1.0\n",
        "        phi_s_next = np.zeros(num_states)\n",
        "        phi_s_next[int(s_next)] = 1.0\n",
        "        A += np.outer(phi_s, (phi_s - gamma * phi_s_next))\n",
        "        b += phi_s * reward\n",
        "    # Add a small regularization term for numerical stability\n",
        "    reg = 1e-5 * np.eye(num_states)\n",
        "    theta = np.linalg.solve(A + reg, b)\n",
        "    return theta\n",
        "\n",
        "def federated_avg(local_thetas):\n",
        "    \"\"\"\n",
        "    Federated averaging: simply compute the mean of local theta estimates.\n",
        "    \"\"\"\n",
        "    return np.mean(local_thetas, axis=0)\n",
        "\n",
        "def compare_federated_vs_centralized(num_hospitals=3, rounds=5):\n",
        "    num_states = 5\n",
        "    global_theta = np.zeros(num_states)\n",
        "\n",
        "    # Federated Learning\n",
        "    print(\"\\n--- Federated LSTD Training ---\")\n",
        "    for r in range(rounds):\n",
        "        local_thetas = []\n",
        "        for hospital in range(num_hospitals):\n",
        "            env = MedicalEnv(num_states)\n",
        "            samples = local_training(env)\n",
        "            theta = LSTD(samples, num_states)\n",
        "            local_thetas.append(theta)\n",
        "        global_theta = federated_avg(local_thetas)\n",
        "        print(f\"Round {r+1}: Averaged Theta: {global_theta.round(3)}\")\n",
        "\n",
        "    print(f\"\\nFinal Federated Theta: {global_theta.round(3)}\")\n",
        "\n",
        "    # Centralized Learning (single node, equivalent amount of data)\n",
        "    print(\"\\n--- Centralized LSTD Training ---\")\n",
        "    env = MedicalEnv(num_states)\n",
        "    centralized_theta = centralized_training(env, num_states, episodes=num_hospitals * 20)\n",
        "    print(f\"\\nFinal Centralized Theta: {centralized_theta.round(3)}\")\n",
        "\n",
        "    # Comparison\n",
        "    print(\"\\n--- Theta Comparison (Federated vs. Centralized) ---\")\n",
        "    for i in range(num_states):\n",
        "        print(f\"State {i}: Federated: {global_theta[i]:.3f} | Centralized: {centralized_theta[i]:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    compare_federated_vs_centralized()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIEU8t1lt9WB",
        "outputId": "ed8b3252-2743-490f-b2b8-eccaab0425ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mpi4py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcvUBzeAt7Du",
        "outputId": "8ff1bc96-d9ac-4fcc-f02e-18be5b05b490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting mpi_federated_lstd.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi_federated_lstd.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "\n",
        "class MedicalEnv:\n",
        "    \"\"\"\n",
        "    A simple medical decision-making environment.\n",
        "    States: 0 (healthy) to num_states-1 (critical).\n",
        "    Terminal states: 0 (recovered) and num_states-1 (severe condition).\n",
        "    Actions: 0 = no treatment, 1 = treatment.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_states=5):\n",
        "        self.num_states = num_states\n",
        "        self.terminal_states = [0, self.num_states - 1]\n",
        "\n",
        "    def reset(self):\n",
        "        # Initialize state to a value between 1 and num_states-2 (i.e., not terminal)\n",
        "        s = np.random.randint(1, self.num_states - 1)\n",
        "        return s\n",
        "\n",
        "    def step(self, s, action):\n",
        "        \"\"\"\n",
        "        Simulate a step in the environment.\n",
        "        - Action 1 (treatment): With 70% chance, state improves (decreases by 1),\n",
        "          with 30% chance, state worsens (increases by 1), if possible.\n",
        "        - Action 0 (no treatment): With 50% chance, state worsens (increases by 1),\n",
        "          otherwise stays the same.\n",
        "        A treatment cost is subtracted from the reward.\n",
        "        Reward is defined as negative of the new state (lower is better) and treatment cost.\n",
        "        \"\"\"\n",
        "        if action == 1:  # Treatment applied\n",
        "            if np.random.rand() < 0.7:\n",
        "                s_next = max(s - 1, 0)\n",
        "            else:\n",
        "                s_next = min(s + 1, self.num_states - 1)\n",
        "            cost = 2  # Treatment cost\n",
        "        else:  # No treatment\n",
        "            if np.random.rand() < 0.5:\n",
        "                s_next = min(s + 1, self.num_states - 1)\n",
        "            else:\n",
        "                s_next = s\n",
        "            cost = 0\n",
        "\n",
        "        reward = - s_next - cost\n",
        "        done = s_next in self.terminal_states\n",
        "        return s_next, reward, done\n",
        "\n",
        "def local_training(env, episodes=20):\n",
        "    \"\"\"\n",
        "    Local training: collect samples from a single hospital (environment).\n",
        "    Each sample is a tuple (state, reward, next_state).\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = np.random.choice([0, 1])\n",
        "            s_next, reward, done = env.step(s, action)\n",
        "            samples.append((s, reward, s_next))\n",
        "            s = s_next\n",
        "    return samples\n",
        "\n",
        "def centralized_training(env, num_states, episodes=60):\n",
        "    \"\"\"\n",
        "    Centralized training on one environment using all data.\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = np.random.choice([0, 1])\n",
        "            s_next, reward, done = env.step(s, action)\n",
        "            samples.append((s, reward, s_next))\n",
        "            s = s_next\n",
        "    theta = LSTD(samples, num_states)\n",
        "    return theta\n",
        "\n",
        "def LSTD(samples, num_states, gamma=0.9):\n",
        "    \"\"\"\n",
        "    Least-Squares Temporal Difference (LSTD) learning.\n",
        "    Uses one-hot encoding for state features.\n",
        "    Solves: A theta = b, where:\n",
        "      A = sum(phi(s) (phi(s)- gamma phi(s_next))^T)\n",
        "      b = sum(phi(s) * reward)\n",
        "    \"\"\"\n",
        "    A = np.zeros((num_states, num_states))\n",
        "    b = np.zeros(num_states)\n",
        "    for s, reward, s_next in samples:\n",
        "        phi_s = np.zeros(num_states)\n",
        "        phi_s[int(s)] = 1.0\n",
        "        phi_s_next = np.zeros(num_states)\n",
        "        phi_s_next[int(s_next)] = 1.0\n",
        "        A += np.outer(phi_s, (phi_s - gamma * phi_s_next))\n",
        "        b += phi_s * reward\n",
        "    reg = 1e-5 * np.eye(num_states)\n",
        "    theta = np.linalg.solve(A + reg, b)\n",
        "    return theta\n",
        "\n",
        "def federated_avg(local_thetas):\n",
        "    \"\"\"\n",
        "    Federated averaging: average local theta estimates.\n",
        "    \"\"\"\n",
        "    return np.mean(local_thetas, axis=0)\n",
        "\n",
        "def federated_training_mpi(rounds=5, num_states=5):\n",
        "    \"\"\"\n",
        "    Federated training using MPI.\n",
        "    Each MPI process represents one hospital.\n",
        "    \"\"\"\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    global_theta = np.zeros(num_states)\n",
        "    for r in range(rounds):\n",
        "        env = MedicalEnv(num_states)\n",
        "        samples = local_training(env, episodes=20)\n",
        "        local_theta = LSTD(samples, num_states)\n",
        "        print(f\"Rank {rank} in round {r+1}: local theta = {local_theta.round(3)}\", flush=True)\n",
        "        theta_sum = np.zeros(num_states)\n",
        "        # Sum all local thetas across processes\n",
        "        comm.Allreduce(local_theta, theta_sum, op=MPI.SUM)\n",
        "        global_theta = theta_sum / size\n",
        "        if rank == 0:\n",
        "            print(f\"Round {r+1}: Averaged Theta: {global_theta.round(3)}\")\n",
        "    return global_theta\n",
        "\n",
        "def compare_federated_vs_centralized_MPI():\n",
        "    \"\"\"\n",
        "    Compare federated vs. centralized LSTD training using MPI.\n",
        "    Rank 0 performs the centralized training and prints comparisons.\n",
        "    \"\"\"\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "    num_states = 5\n",
        "\n",
        "    if rank == 0:\n",
        "        print(\"\\n--- Federated LSTD Training (MPI) ---\")\n",
        "    global_theta = federated_training_mpi(rounds=5, num_states=num_states)\n",
        "\n",
        "    # if rank == 0:\n",
        "    #     print(f\"\\nFinal Federated Theta: {global_theta.round(3)}\")\n",
        "    #     print(\"\\n--- Centralized LSTD Training ---\")\n",
        "    #     env = MedicalEnv(num_states)\n",
        "    #     # Use an equivalent amount of episodes: total episodes = (num_hospitals * 20)\n",
        "    #     centralized_theta = centralized_training(env, num_states, episodes=size * 20)\n",
        "    #     print(f\"\\nFinal Centralized Theta: {centralized_theta.round(3)}\")\n",
        "    #     print(\"\\n--- Theta Comparison (Federated vs. Centralized) ---\")\n",
        "    #     for i in range(num_states):\n",
        "    #         print(f\"State {i}: Federated: {global_theta[i]:.3f} | Centralized: {centralized_theta[i]:.3f}\")\n",
        "\n",
        "    if rank == 0:\n",
        "        print(\"\\n--- Federated LSTD Training (MPI) ---\", flush=True)\n",
        "    global_theta = federated_training_mpi(rounds=5, num_states=num_states)\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f\"\\nFinal Federated Theta: {global_theta.round(3)}\", flush=True)\n",
        "        print(\"\\n--- Centralized LSTD Training ---\", flush=True)\n",
        "        env = MedicalEnv(num_states)\n",
        "        centralized_theta = centralized_training(env, num_states, episodes=size * 20)\n",
        "        print(f\"\\nFinal Centralized Theta: {centralized_theta.round(3)}\", flush=True)\n",
        "        print(\"\\n--- Theta Comparison (Federated vs. Centralized) ---\", flush=True)\n",
        "        for i in range(num_states):\n",
        "            print(f\"State {i}: Federated: {global_theta[i]:.3f} | Centralized: {centralized_theta[i]:.3f}\", flush=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    compare_federated_vs_centralized_MPI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w0Clncixz2Fi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------\n",
            "prterun was unable to find the specified executable file, and therefore did\n",
            "not launch the job.  This error was first reported for process rank\n",
            "0; it may have occurred for other processes as well.\n",
            "\n",
            "NOTE: A common cause for this error is misspelling a prterun command\n",
            "   line parameter option (remember that prterun interprets the first\n",
            "   unrecognized command line token as the executable).\n",
            "\n",
            "   Node:       Hitens-Macbook-Pro\n",
            "   Executable: python\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!mpiexec --allow-run-as-root -n 3 python mpi_federated_lstd.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS1miJlZ72jA"
      },
      "source": [
        "Try this on ADA HPC of IIIT-H"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
